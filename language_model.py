import requests
import json

class LocalLLM:
    def __init__(self, ollama_url="http://localhost:11434", model="mistral"):
        self.url = ollama_url
        self.model = model
        self.conversation_history = []
        self.system_prompt = (
            "Voc√™ √© JASP, um assistente de laborat√≥rio de programa√ß√£o e eletr√¥nica. "
            "Voc√™ fala como um desenvolvedor experiente, educado, direto e tranquilo. "
            "Use um tom humano, com frases curtas, √†s vezes express√µes como 'beleza', 'vamos l√°', "
            "mas sem g√≠rias pesadas ou palavr√µes. "
            "Explique as coisas de forma pr√°tica, como se estivesse ajudando um colega. "
            "Sempre responda em portugu√™s do Brasil."
        )
    
    def set_modo_serio(self):
        """
        Deixa o JASP em modo s√©rio: t√©cnico, claro, mas ainda humano.
        """
        self.system_prompt = (
            "Voc√™ √© JASP, um assistente t√©cnico s√©rio, calmo e confi√°vel. "
            "Seu foco √© ajudar com programa√ß√£o, eletr√¥nica e d√∫vidas gerais de forma clara e objetiva. "
            "Voc√™ evita g√≠rias, n√£o usa palavr√µes e fala de maneira educada e profissional, "
            "como um professor que realmente quer que o aluno entenda. "
            "Use frases curtas, exemplos simples e, quando a pergunta for confusa, pe√ßa clarifica√ß√£o. "
            "Sempre responda em portugu√™s do Brasil."
        )
        self.conversation_history = []

    def process_message(self, user_input):
        """Processa mensagem do usu√°rio e gera resposta"""
        # Adicionar hist√≥rico
        self.conversation_history.append({
            "role": "user",
            "content": user_input
        })
        
        # Preparar contexto
        messages = [{"role": "system", "content": self.system_prompt}]
        messages.extend(self.conversation_history[-6:])  # √öltimas 3 trocas
        
        try:
            response = requests.post(
                f"{self.url}/api/chat",
                json={
                    "model": self.model,
                    "messages": messages,
                    "stream": False,
                    "temperature": 0.7,
                },
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                assistant_message = result["message"]["content"]
                
                # Adicionar resposta ao hist√≥rico
                self.conversation_history.append({
                    "role": "assistant",
                    "content": assistant_message
                })
                
                return assistant_message
            else:
                return "Desculpe, n√£o consegui processar sua solicita√ß√£o."
        
        except Exception as e:
            print(f"Erro ao conectar com LLM: {e}")
            return "Erro na comunica√ß√£o com o modelo."
        
    def set_system_prompt(self, prompt: str):
        """Permite trocar a personalidade do JASP em tempo real."""
        self.system_prompt = prompt
        # opcional: limpar hist√≥rico para n√£o misturar personalidades
        self.conversation_history = []

    def answer_with_web(self, user_input: str, web_text: str):
        """
        Faz o LLM responder usando o texto da web como contexto adicional.
        """
        contexto = (
            "Use as informa√ß√µes abaixo, extra√≠das da internet, para responder.\n\n"
            f"INFORMA√á√ïES DA WEB:\n{web_text}\n\n"
            f"PERGUNTA DO USU√ÅRIO:\n{user_input}\n\n"
            "Responda em portugu√™s do Brasil, curto e direto."
        )
        return self.process_message(contexto)
    
    def clear_history(self):
        """Limpa hist√≥rico de conversa"""
        self.conversation_history = []

# Uso
if __name__ == "__main__":
    llm = LocalLLM()
    
    test_messages = [
        "Bom dia, Jasp",
        "Como integrar Python com Arduino?",
        "Me explique sobre GPIO",
        "Como integrar Banco de Dados com Arduino?",
        "Como integrar Banco de Dados em Python?"
    ]
    
    for msg in test_messages:
        print(f"\nüë§ Usu√°rio: {msg}")
        response = llm.process_message(msg)
        print(f"ü§ñ JARVIS: {response}")
